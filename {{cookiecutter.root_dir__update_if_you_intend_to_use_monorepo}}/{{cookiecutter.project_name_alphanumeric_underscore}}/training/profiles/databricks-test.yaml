experiment:
  # The name of the experiment to use during training or model validation in test environment.
  # This value must be the same as experiment_name defined in
<<<<<<< HEAD
  # {{cookiecutter.project_name_alphanumeric_underscore}}/bundle.yml for test environment.
=======
  # {{cookiecutter.project_name_alphanumeric_underscore}}/databricks-resources/ml-artifacts-bundle-resource.yml for test environment.
>>>>>>> 3b0f973 (Address bug bash issues and polish stacks for private preview)
  name: /test-{{cookiecutter.experiment_base_name}}

# Set the registry server URI. This property is especially useful if you have a registry
# server thatâ€™s different from the tracking server.
model_registry:
  # Specifies the name of the Registered Model to use when registering a trained model to
  # the MLflow Model Registry
  # This value must be the same as model_name defined in
<<<<<<< HEAD
  # {{cookiecutter.project_name_alphanumeric_underscore}}/bundle.yml for test environment.
=======
  # {{cookiecutter.project_name_alphanumeric_underscore}}/databricks-resources/ml-artifacts-bundle-resource.yml for test environment.
>>>>>>> 3b0f973 (Address bug bash issues and polish stacks for private preview)
  model_name: test-{{cookiecutter.model_name}}

# Override the default train / validation / test dataset split ratios
SPLIT_RATIOS: [0.75, 0.125, 0.125]

INGEST_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#ingest-step
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: update this field to point to the path to your model training dataset on your staging Databricks workspace,
  # to be used in tests. For example, you may want to create a down-sampled version of your full production dataset
  # and specify its path here.
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

INGEST_SCORING_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#batch-scoring
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: Specify the name/path of the input table for batch inference tests here
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

PREDICT_OUTPUT_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#predict-step
  # Specify the output format of the batch scoring predict step
  using: table
  # TODO: Specify the name of the output table for batch inference in tests here
  location: "{{cookiecutter.project_name}}_batch_scoring_test"
