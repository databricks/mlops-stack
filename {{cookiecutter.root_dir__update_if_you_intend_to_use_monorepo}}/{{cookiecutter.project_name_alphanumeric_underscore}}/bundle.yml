variables:
  experiment_name:
    description: Experiment name for the model training.
    default: /Users/${workspace.current_user.userName}/${bundle.environment}-{{cookiecutter.experiment_base_name}}
  model_name:
    description: Model name for the model training.
    default: ${bundle.environment}-{{cookiecutter.model_name}}
  model_description:
    description: Model description for the model used in training.
    default: MLflow registered model for the "{{cookiecutter.project_name}}" ML Project for ${bundle.environment} environment.


bundle:
  name: {{cookiecutter.project_name}}


include:
  # Include ML artifact resources for the ml project
  # Defines model and experiment
  - ./databricks-resource/ml-artifacts-resource.yml

  # Include workflow resources of the ml project
  # Defines workflow for model training -> validation -> deployment
  - ./databricks-resource/model-workflow-resource.yml
  {%- if cookiecutter.include_feature_store == "yes" %}
  # Defines workflow for feature engineering
  - ./databricks-resource/feature-engineering-workflow-resource.yml{% endif %}
  # Defines workflow for scheduled batch inference
  - ./databricks-resource/batch-inference-workflow-resource.yml
  # Defines workflow for data monitoring, metric refresh, alerts and triggering retraining
  - ./databricks-resource/monitoring-workflow-resource.yml


# Environment specific values for workspace
environments:
  dev:
    default: true
    workspace:
      # TODO: add dev workspace URL
      host:

  staging:
    workspace:
      host: {{cookiecutter.databricks_staging_workspace_host}}

  prod:
    variables:
      model_description: |
        MLflow registered model for the "{{cookiecutter.project_name}}" ML Project. See the corresponding [Git repo](${bundle.git.origin_url}) for details on the project.
        
        Links:
          * [Git Repo](${bundle.git.origin_url}): contains ML code for the current project.
          * [Recurring model training job]({{cookiecutter.databricks_staging_workspace_host}}#job/${resources.jobs.model_training_job.id}): trains fresh model versions using the latest ML code.
          * [Recurring batch inference job]({{cookiecutter.databricks_staging_workspace_host}}#job/${resources.jobs.batch_inference_job.id}): applies the latest ${bundle.environment} model version for batch inference.
    workspace:
      host: {{cookiecutter.databricks_prod_workspace_host}}

  test:
    workspace:
      host: {{cookiecutter.databricks_staging_workspace_host}}

